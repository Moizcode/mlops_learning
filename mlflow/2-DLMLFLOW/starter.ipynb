{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from hyperopt import STATUS_OK,Trials,fmin,hp,tpe\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import mlflow\n",
    "from mlflow.models import infer_signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.00100</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.99400</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.99510</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.99560</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4898 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.0              0.27         0.36            20.7      0.045   \n",
       "1               6.3              0.30         0.34             1.6      0.049   \n",
       "2               8.1              0.28         0.40             6.9      0.050   \n",
       "3               7.2              0.23         0.32             8.5      0.058   \n",
       "4               7.2              0.23         0.32             8.5      0.058   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "4893            6.2              0.21         0.29             1.6      0.039   \n",
       "4894            6.6              0.32         0.36             8.0      0.047   \n",
       "4895            6.5              0.24         0.19             1.2      0.041   \n",
       "4896            5.5              0.29         0.30             1.1      0.022   \n",
       "4897            6.0              0.21         0.38             0.8      0.020   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    45.0                 170.0  1.00100  3.00       0.45   \n",
       "1                    14.0                 132.0  0.99400  3.30       0.49   \n",
       "2                    30.0                  97.0  0.99510  3.26       0.44   \n",
       "3                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "4                    47.0                 186.0  0.99560  3.19       0.40   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "4893                 24.0                  92.0  0.99114  3.27       0.50   \n",
       "4894                 57.0                 168.0  0.99490  3.15       0.46   \n",
       "4895                 30.0                 111.0  0.99254  2.99       0.46   \n",
       "4896                 20.0                 110.0  0.98869  3.34       0.38   \n",
       "4897                 22.0                  98.0  0.98941  3.26       0.32   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         8.8        6  \n",
       "1         9.5        6  \n",
       "2        10.1        6  \n",
       "3         9.9        6  \n",
       "4         9.9        6  \n",
       "...       ...      ...  \n",
       "4893     11.2        6  \n",
       "4894      9.6        5  \n",
       "4895      9.4        6  \n",
       "4896     12.8        7  \n",
       "4897     11.8        6  \n",
       "\n",
       "[4898 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\n",
    "    \"https://raw.githubusercontent.com/mlflow/mlflow/master/tests/datasets/winequality-white.csv\",\n",
    "    sep=\";\"\n",
    ")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### split data into training, testing and validation\n",
    "\n",
    "train,test = train_test_split(data,test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train.drop(['quality'],axis=1).values\n",
    "train_y = train['quality'].values.ravel()\n",
    "\n",
    "## testing dataset\n",
    "test_x = test.drop(['quality'],axis=1).values\n",
    "test_y = test['quality'].values.ravel()\n",
    "\n",
    "train_x,valid_x,train_y,valid_y = train_test_split(train_x,train_y,test_size=0.2,random_state=42)\n",
    "\n",
    "signature = infer_signature(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### ANN Model\n",
    "\n",
    "def train_model(params,epochs,train_x,train_y,valid_x,valid_y,test_x,test_y):\n",
    "\n",
    "    ## model architecture\n",
    "    mean = np.mean(train_x,axis=0)\n",
    "    var = np.var(train_x,axis=0)\n",
    "\n",
    "    model = keras.Sequential([\n",
    "        keras.Input([train_x.shape[1]]),\n",
    "        keras.layers.Normalization(mean=mean,variance=var),\n",
    "        keras.layers.Dense(64,activation='relu'),\n",
    "        keras.layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "\n",
    "    ## compile the model \n",
    "    model.compile(optimizer=keras.optimizers.SGD(\n",
    "                  learning_rate = params['lr'], momentum = params['momentum']\n",
    "                  ),\n",
    "                  loss='mean_squared_error',\n",
    "                  metrics =[ keras.metrics.RootMeanSquaredError()]\n",
    "                  )\n",
    "    \n",
    "    ## Train ANN model with lr and momentum with mlflow tracking\n",
    "    with mlflow.start_run(nested=True):\n",
    "        model.fit(train_x,train_y,validation_data=(valid_x,valid_y),\n",
    "                  epochs=epochs,\n",
    "                  batch_size=32)\n",
    "        \n",
    "        ##evaluate the model\n",
    "        eval_result = model.evaluate(valid_x,valid_y,batch_size=32)\n",
    "\n",
    "        eval_rmse = eval_result[1]\n",
    "\n",
    "        ## log the parameteres and results\n",
    "        # Log each parameter\n",
    "        for param_name, param_value in params.items():\n",
    "            mlflow.log_param(param_name, param_value)\n",
    "        mlflow.log_metric('rmse',eval_rmse)\n",
    "\n",
    "        ### log model \n",
    "        mlflow.tensorflow.log_model(model,\"model\",signature=signature)\n",
    "\n",
    "        return {'loss':eval_rmse,\"status\":STATUS_OK,\"model\":model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    result = train_model(\n",
    "        params,\n",
    "        epochs=3,\n",
    "        train_x= train_x,\n",
    "        train_y= train_y,\n",
    "        test_x= test_x,\n",
    "        valid_x=valid_x,\n",
    "        valid_y=valid_y,\n",
    "        test_y=test_y\n",
    "    )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    'lr' :hp.loguniform(\"lr\",np.log(1e-5),np.log(1e-1)),\n",
    "    'momentum':hp.uniform(\"momentum\",0.0,1.0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/02 19:10:02 INFO mlflow.tracking.fluent: Experiment with name '/wine-quality' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3                                            \n",
      "\n",
      "\u001b[1m 1/92\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m39s\u001b[0m 438ms/step - loss: 35.6628 - root_mean_squared_error: 5.9718\n",
      "\u001b[1m35/92\u001b[0m \u001b[32m━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 30.9313 - root_mean_squared_error: 5.5598   \n",
      "\u001b[1m69/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 27.5208 - root_mean_squared_error: 5.2316\n",
      "\u001b[1m90/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 25.2682 - root_mean_squared_error: 4.9967\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 24.9673 - root_mean_squared_error: 4.9643 - val_loss: 3.8191 - val_root_mean_squared_error: 1.9542\n",
      "\n",
      "Epoch 2/3                                            \n",
      "\n",
      "\u001b[1m 1/92\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - loss: 3.4789 - root_mean_squared_error: 1.8652\n",
      "\u001b[1m32/92\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 4.7126 - root_mean_squared_error: 2.1605 \n",
      "\u001b[1m64/92\u001b[0m \u001b[32m━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 5.5760 - root_mean_squared_error: 2.3488\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 5.7763 - root_mean_squared_error: 2.3938 - val_loss: 2.3833 - val_root_mean_squared_error: 1.5438\n",
      "\n",
      "Epoch 3/3                                            \n",
      "\n",
      "\u001b[1m 1/92\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - loss: 2.5163 - root_mean_squared_error: 1.5863\n",
      "\u001b[1m27/92\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.3102 - root_mean_squared_error: 1.5196 \n",
      "\u001b[1m57/92\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.3362 - root_mean_squared_error: 1.5282\n",
      "\u001b[1m89/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.4477 - root_mean_squared_error: 1.5636\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.4610 - root_mean_squared_error: 1.5677 - val_loss: 2.9913 - val_root_mean_squared_error: 1.7295\n",
      "\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 2.6472 - root_mean_squared_error: 1.6270\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.8507 - root_mean_squared_error: 1.6876 \n",
      "\n",
      "Epoch 1/3                                                                      \n",
      "\n",
      "\u001b[1m 1/92\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m54s\u001b[0m 603ms/step - loss: 30.9235 - root_mean_squared_error: 5.5609\n",
      "\u001b[1m22/92\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 24.8467 - root_mean_squared_error: 4.9702   \n",
      "\u001b[1m38/92\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 21.1725 - root_mean_squared_error: 4.5664\n",
      "\u001b[1m56/92\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 18.2361 - root_mean_squared_error: 4.2129\n",
      "\u001b[1m81/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 15.4435 - root_mean_squared_error: 3.8475\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 14.4447 - root_mean_squared_error: 3.7091 - val_loss: 2.2837 - val_root_mean_squared_error: 1.5112\n",
      "\n",
      "Epoch 2/3                                                                      \n",
      "\n",
      "\u001b[1m 1/92\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m5s\u001b[0m 61ms/step - loss: 1.5426 - root_mean_squared_error: 1.2420\n",
      "\u001b[1m24/92\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.1887 - root_mean_squared_error: 1.4766 \n",
      "\u001b[1m47/92\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.1072 - root_mean_squared_error: 1.4498\n",
      "\u001b[1m70/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.0575 - root_mean_squared_error: 1.4329\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.0116 - root_mean_squared_error: 1.4169 - val_loss: 1.6314 - val_root_mean_squared_error: 1.2773\n",
      "\n",
      "Epoch 3/3                                                                      \n",
      "\n",
      "\u001b[1m 1/92\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - loss: 2.0861 - root_mean_squared_error: 1.4443\n",
      "\u001b[1m25/92\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.6851 - root_mean_squared_error: 1.2966 \n",
      "\u001b[1m50/92\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5682 - root_mean_squared_error: 1.2506\n",
      "\u001b[1m71/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.5141 - root_mean_squared_error: 1.2288\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 1.4815 - root_mean_squared_error: 1.2156 - val_loss: 1.3420 - val_root_mean_squared_error: 1.1585\n",
      "\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 1.0241 - root_mean_squared_error: 1.0120\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.3319 - root_mean_squared_error: 1.1533 \n",
      "\n",
      "Epoch 1/3                                                                      \n",
      "\n",
      "\u001b[1m 1/92\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m43s\u001b[0m 483ms/step - loss: 29.1115 - root_mean_squared_error: 5.3955\n",
      "\u001b[1m32/92\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 29.3351 - root_mean_squared_error: 5.4161   \n",
      "\u001b[1m58/92\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 29.4789 - root_mean_squared_error: 5.4294\n",
      "\u001b[1m86/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 29.4932 - root_mean_squared_error: 5.4307\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 29.4878 - root_mean_squared_error: 5.4302 - val_loss: 29.0707 - val_root_mean_squared_error: 5.3917\n",
      "\n",
      "Epoch 2/3                                                                      \n",
      "\n",
      "\u001b[1m 1/92\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - loss: 27.7791 - root_mean_squared_error: 5.2706\n",
      "\u001b[1m23/92\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 28.7593 - root_mean_squared_error: 5.3626 \n",
      "\u001b[1m45/92\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 28.6358 - root_mean_squared_error: 5.3512\n",
      "\u001b[1m67/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 28.5997 - root_mean_squared_error: 5.3478\n",
      "\u001b[1m87/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 28.6035 - root_mean_squared_error: 5.3482\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 28.6069 - root_mean_squared_error: 5.3485 - val_loss: 28.3021 - val_root_mean_squared_error: 5.3200\n",
      "\n",
      "Epoch 3/3                                                                      \n",
      "\n",
      "\u001b[1m 1/92\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 24.6180 - root_mean_squared_error: 4.9617\n",
      "\u001b[1m26/92\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 27.9489 - root_mean_squared_error: 5.2861 \n",
      "\u001b[1m49/92\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 28.0046 - root_mean_squared_error: 5.2916\n",
      "\u001b[1m71/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 27.9758 - root_mean_squared_error: 5.2890\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.9481 - root_mean_squared_error: 5.2864 - val_loss: 27.5526 - val_root_mean_squared_error: 5.2491\n",
      "\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 27.5037 - root_mean_squared_error: 5.2444\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 27.2575 - root_mean_squared_error: 5.2208 \n",
      "\n",
      "Epoch 1/3                                                                      \n",
      "\n",
      "\u001b[1m 1/92\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m44s\u001b[0m 488ms/step - loss: 36.0320 - root_mean_squared_error: 6.0027\n",
      "\u001b[1m28/92\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 30.3706 - root_mean_squared_error: 5.5039   \n",
      "\u001b[1m54/92\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 26.4377 - root_mean_squared_error: 5.1209\n",
      "\u001b[1m79/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 23.5664 - root_mean_squared_error: 4.8183\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 22.2113 - root_mean_squared_error: 4.6674 - val_loss: 3.6095 - val_root_mean_squared_error: 1.8999\n",
      "\n",
      "Epoch 2/3                                                                      \n",
      "\n",
      "\u001b[1m 1/92\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - loss: 3.3315 - root_mean_squared_error: 1.8252\n",
      "\u001b[1m28/92\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.1981 - root_mean_squared_error: 1.7874 \n",
      "\u001b[1m56/92\u001b[0m \u001b[32m━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 3.0006 - root_mean_squared_error: 1.7308\n",
      "\u001b[1m83/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.8649 - root_mean_squared_error: 1.6905\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 2.8203 - root_mean_squared_error: 1.6771 - val_loss: 1.9473 - val_root_mean_squared_error: 1.3954\n",
      "\n",
      "Epoch 3/3                                                                      \n",
      "\n",
      "\u001b[1m 1/92\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - loss: 1.2468 - root_mean_squared_error: 1.1166\n",
      "\u001b[1m25/92\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 2.0425 - root_mean_squared_error: 1.4237 \n",
      "\u001b[1m41/92\u001b[0m \u001b[32m━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.9636 - root_mean_squared_error: 1.3975\n",
      "\u001b[1m66/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 1.8953 - root_mean_squared_error: 1.3739\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.8505 - root_mean_squared_error: 1.3581 - val_loss: 1.6740 - val_root_mean_squared_error: 1.2938\n",
      "\n",
      "\u001b[1m 1/23\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - loss: 1.4225 - root_mean_squared_error: 1.1927\n",
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 1.6983 - root_mean_squared_error: 1.3021 \n",
      "\n",
      "100%|██████████| 4/4 [00:47<00:00, 11.87s/trial, best loss: 1.1584599018096924]\n",
      "Best parameters: {'lr': np.float64(0.0012728775242066893), 'momentum': np.float64(0.5919792374476864)}\n",
      "Best Eval Rmse: 1.1584599018096924\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"/wine-quality\")\n",
    "with mlflow.start_run():\n",
    "    # conduct the hyperparameter search using hpyeropt\n",
    "    trails = Trials()\n",
    "    best = fmin(\n",
    "        fn = objective,\n",
    "        space = space,\n",
    "        algo= tpe.suggest,\n",
    "        max_evals=4,\n",
    "        trials=trails\n",
    "    )\n",
    "    \n",
    "\n",
    "    # fetch the details of best run\n",
    "    best_run = sorted(trails.results,key=lambda x:x['loss'])[0]\n",
    "\n",
    "    # log the best parameters\n",
    "    # Log each parameter\n",
    "    for param_name, param_value in best.items():\n",
    "        mlflow.log_param(param_name, param_value)\n",
    "    mlflow.log_metric(\"eval_rmse\", best_run[\"loss\"])\n",
    "    mlflow.tensorflow.log_model(best_run['model'],\"model\",signature=signature)\n",
    "\n",
    "    print(f\"Best parameters: {best}\")\n",
    "    print(f\"Best Eval Rmse: {best_run['loss']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\moiz.DESKTOP-EOSKFCV\\anaconda3\\envs\\mlops\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 538.80it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m39/39\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4.176057 ],\n",
       "       [6.7754583],\n",
       "       [5.7462425],\n",
       "       ...,\n",
       "       [7.449068 ],\n",
       "       [6.9104137],\n",
       "       [4.769905 ]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## inferencing\n",
    "from mlflow.models import validate_serving_input\n",
    "\n",
    "model_uri = 'runs:/8159df3f0030465b9011aebc9b9d80db/model'\n",
    "\n",
    "# The logged model does not contain an input_example.\n",
    "# Manually generate a serving payload to verify your model prior to deployment.\n",
    "from mlflow.models import convert_input_example_to_serving_input\n",
    "\n",
    "# Define INPUT_EXAMPLE via assignment with your own input example to the model\n",
    "# A valid input example is a data instance suitable for pyfunc prediction\n",
    "serving_payload = convert_input_example_to_serving_input(test_x)\n",
    "\n",
    "# Validate the serving payload works on the model\n",
    "validate_serving_input(model_uri, serving_payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
